{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed0981be-b2df-49a8-8925-b947c48939d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CourseAnalytics\").getOrCreate()\n",
    "df = spark.read.csv(\"file:/Workspace/Shared/course_enrollments.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1c3243a-8c3d-4f50-9b77-de6821a3cb98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|IsCompleted|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     4|             9|          1|\n|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|     0|          NULL|          0|\n|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|     0|          NULL|          0|\n|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|            16|          1|\n|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|            11|          1|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, datediff, to_date, when\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Convert EnrollDate and CompletionDate to DateType\n",
    "df = df.withColumn(\"EnrollDate\", to_date(\"EnrollDate\", \"yyyy-MM-dd\")) \\\n",
    "       .withColumn(\"CompletionDate\", to_date(\"CompletionDate\", \"yyyy-MM-dd\"))\n",
    "\n",
    "# Add DaysToComplete column if completed\n",
    "df = df.withColumn(\"DaysToComplete\", when(col(\"CompletionDate\").isNotNull(), datediff(\"CompletionDate\", \"EnrollDate\"))\n",
    "                   .otherwise(None))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ab6227d-d553-4e10-b7c2-fe68b7887d77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+-----------+----------------+\n|UserID|CoursesEnrolled|AvgProgress|CompletedCourses|\n+------+---------------+-----------+----------------+\n|  U004|              1|      100.0|               1|\n|  U002|              1|       45.0|               0|\n|  U003|              1|      100.0|               1|\n|  U001|              2|       65.0|               1|\n+------+---------------+-----------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, count, expr, when, col\n",
    "\n",
    "#Flag IsCompleted = ProgressPercent = 100\n",
    "df = df.withColumn(\"IsCompleted\", when(col(\"ProgressPercent\") == 100, 1).otherwise(0))\n",
    "\n",
    "# Group by UserID : count of courses enrolled\n",
    "#Avg progress % across all enrollments\n",
    "\n",
    "user_progress = df.groupBy(\"UserID\").agg(count(\"*\").alias(\"CoursesEnrolled\"),\n",
    "    avg(\"ProgressPercent\").alias(\"AvgProgress\"),\n",
    "    expr(\"sum(IsCompleted)\").alias(\"CompletedCourses\")\n",
    ")\n",
    "user_progress.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "972006b1-3de9-4c68-a120-92db511eb94f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EnrollID</th><th>UserID</th><th>CourseID</th><th>CourseName</th><th>Category</th><th>EnrollDate</th><th>CompletionDate</th><th>ProgressPercent</th><th>Rating</th><th>DaysToComplete</th><th>IsCompleted</th><th>EngagementScore</th></tr></thead><tbody><tr><td>E001</td><td>U001</td><td>C001</td><td>Python Basics</td><td>Programming</td><td>2024-04-01</td><td>2024-04-10</td><td>100</td><td>4</td><td>9</td><td>1</td><td>400</td></tr><tr><td>E002</td><td>U002</td><td>C002</td><td>Excel for Finance</td><td>Productivity</td><td>2024-04-02</td><td>null</td><td>45</td><td>0</td><td>null</td><td>0</td><td>0</td></tr><tr><td>E003</td><td>U001</td><td>C003</td><td>ML with PySpark</td><td>Data Science</td><td>2024-04-03</td><td>null</td><td>30</td><td>0</td><td>null</td><td>0</td><td>0</td></tr><tr><td>E004</td><td>U003</td><td>C001</td><td>Python Basics</td><td>Programming</td><td>2024-04-04</td><td>2024-04-20</td><td>100</td><td>5</td><td>16</td><td>1</td><td>500</td></tr><tr><td>E005</td><td>U004</td><td>C004</td><td>Digital Marketing</td><td>Marketing</td><td>2024-04-05</td><td>2024-04-16</td><td>100</td><td>4</td><td>11</td><td>1</td><td>400</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "E001",
         "U001",
         "C001",
         "Python Basics",
         "Programming",
         "2024-04-01",
         "2024-04-10",
         100,
         4,
         9,
         1,
         400
        ],
        [
         "E002",
         "U002",
         "C002",
         "Excel for Finance",
         "Productivity",
         "2024-04-02",
         null,
         45,
         0,
         null,
         0,
         0
        ],
        [
         "E003",
         "U001",
         "C003",
         "ML with PySpark",
         "Data Science",
         "2024-04-03",
         null,
         30,
         0,
         null,
         0,
         0
        ],
        [
         "E004",
         "U003",
         "C001",
         "Python Basics",
         "Programming",
         "2024-04-04",
         "2024-04-20",
         100,
         5,
         16,
         1,
         500
        ],
        [
         "E005",
         "U004",
         "C004",
         "Digital Marketing",
         "Marketing",
         "2024-04-05",
         "2024-04-16",
         100,
         4,
         11,
         1,
         400
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EnrollID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "UserID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CourseID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CourseName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "EnrollDate",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "CompletionDate",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "ProgressPercent",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Rating",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "DaysToComplete",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "IsCompleted",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "EngagementScore",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3. Engagement Scoring\n",
    "\n",
    "# Replace null Rating with 0\n",
    "df = df.withColumn(\"Rating\", when(col(\"Rating\").isNull(), 0).otherwise(col(\"Rating\")))\n",
    "\n",
    "# Create EngagementScore = ProgressPercent * Rating\n",
    "df.withColumn(\"EngagementScore\", (col(\"ProgressPercent\") * col(\"Rating\")).cast(IntegerType())).display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c647e0bb-12eb-419e-b117-0b1282c43aee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|IsCompleted|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|     0|          NULL|          0|\n|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|     0|          NULL|          0|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Identify Drop-offs\n",
    "# Filter all records with ProgressPercent < 50 and CompletionDate is null\n",
    "# Create a view called Dropouts\n",
    "# Filter drop-off records\n",
    "\n",
    "dropouts = df.filter((col(\"ProgressPercent\") < 50) & (col(\"CompletionDate\").isNull()))\n",
    "\n",
    "dropouts.createOrReplaceTempView(\"Dropouts\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM Dropouts\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13c8f788-14e8-4b31-b346-a15860e7499f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n|   Instructor|AvgProgress|\n+-------------+-----------+\n|  Zoya Sheikh|      100.0|\n|   Sana Gupta|       45.0|\n| Ibrahim Khan|       30.0|\n|Abdullah Khan|      100.0|\n+-------------+-----------+\n\n+--------+-------------+-----------+\n|CourseID|   Instructor|Enrollments|\n+--------+-------------+-----------+\n|    C001|Abdullah Khan|          2|\n+--------+-------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Joins with Metadata\n",
    "# Create course_catalog.csv :\n",
    "# CourseID,Instructor,DurationHours,Level\n",
    "# C001,Abdullah Khan,8,Beginner\n",
    "# C002,Sana Gupta,5,Beginner\n",
    "# C003,Ibrahim Khan,10,Intermediate\n",
    "# C004,Zoya Sheikh,6,Beginner\n",
    "\n",
    "catalog_df = spark.read.csv(\"file:/Workspace/Shared/course_catalog.csv\", header=True, inferSchema=True)\n",
    "joined_df = df.join(catalog_df, on=\"CourseID\", how=\"left\")\n",
    "\n",
    "# Join to find average progress per instructor\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "avg_progress = joined_df.groupBy(\"Instructor\").agg(avg(\"ProgressPercent\").alias(\"AvgProgress\"))\n",
    "avg_progress.show()\n",
    "\n",
    "# Show who teaches the most enrolled course\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "most_enrolled = df.groupBy(\"CourseID\").agg(count(\"*\").alias(\"Enrollments\"))\n",
    "top_course= most_enrolled.orderBy(col(\"Enrollments\").desc()).limit(1)\n",
    "\n",
    "instructor_df= top_course.join(catalog_df, on=\"CourseID\", how=\"left\")\n",
    "instructor_df.select(\"CourseID\", \"Instructor\", \"Enrollments\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77c0976a-199d-44d1-b0f5-8dae3e7d9fe5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+----------------+----------------------------------+---------+------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\n|version|timestamp              |userId          |userName                          |operation|operationParameters                                                           |job |notebook          |clusterId           |readVersion|isolationLevel   |isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                          |userMetadata|engineInfo                                |\n+-------+-----------------------+----------------+----------------------------------+---------+------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\n|22     |2025-06-19 07:02:51    |3359264194789707|azuser3558_mml.local@techademy.com|DELETE   |{predicate -> [\"(ProgressPercent#26759 = 0)\"]}                                |NULL|{3428140736495296}|0611-041524-ifuhl15z|21         |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 190, numDeletionVectorsUpdated -> 0, numDeletedRows -> 0, scanTimeMs -> 190, numAddedFiles -> 0, numAddedBytes -> 0, rewriteTimeMs -> 0}      |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|21     |2025-06-19 07:02:50    |3359264194789707|azuser3558_mml.local@techademy.com|UPDATE   |{predicate -> [\"(CourseName#26755 = Python Basics)\"]}                         |NULL|{3428140736495296}|0611-041524-ifuhl15z|20         |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 1, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 1017, numDeletionVectorsUpdated -> 0, scanTimeMs -> 438, numAddedFiles -> 1, numUpdatedRows -> 2, numAddedBytes -> 2891, rewriteTimeMs -> 577}|NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|20     |2025-06-19 07:02:48    |3359264194789707|azuser3558_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                  |NULL|{3428140736495296}|0611-041524-ifuhl15z|19         |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 3112}                                                                                                                                                                                                                                                               |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|19     |2025-06-19 07:02:33    |3359264194789707|azuser3558_mml.local@techademy.com|OPTIMIZE |{predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0}|NULL|{3428140736495296}|0611-041524-ifuhl15z|18         |SnapshotIsolation|false        |{numRemovedFiles -> 2, numRemovedBytes -> 6003, p25FileSize -> 3120, numDeletionVectorsRemoved -> 1, minFileSize -> 3120, numAddedFiles -> 1, maxFileSize -> 3120, p75FileSize -> 3120, p50FileSize -> 3120, numAddedBytes -> 3120}                                                                                       |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|18     |2025-06-19 07:02:31    |3359264194789707|azuser3558_mml.local@techademy.com|DELETE   |{predicate -> [\"(ProgressPercent#23857 = 0)\"]}                                |NULL|{3428140736495296}|0611-041524-ifuhl15z|17         |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 189, numDeletionVectorsUpdated -> 0, numDeletedRows -> 0, scanTimeMs -> 189, numAddedFiles -> 0, numAddedBytes -> 0, rewriteTimeMs -> 0}      |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|17     |2025-06-19 07:02:30    |3359264194789707|azuser3558_mml.local@techademy.com|UPDATE   |{predicate -> [\"(CourseName#23853 = Python Basics)\"]}                         |NULL|{3428140736495296}|0611-041524-ifuhl15z|16         |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 1, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 1101, numDeletionVectorsUpdated -> 0, scanTimeMs -> 466, numAddedFiles -> 1, numUpdatedRows -> 2, numAddedBytes -> 2891, rewriteTimeMs -> 635}|NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|16     |2025-06-19 07:02:28    |3359264194789707|azuser3558_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                  |NULL|{3428140736495296}|0611-041524-ifuhl15z|15         |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 3112}                                                                                                                                                                                                                                                               |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|15     |2025-06-19 07:02:18    |3359264194789707|azuser3558_mml.local@techademy.com|OPTIMIZE |{predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0}|NULL|{3428140736495296}|0611-041524-ifuhl15z|14         |SnapshotIsolation|false        |{numRemovedFiles -> 2, numRemovedBytes -> 6003, p25FileSize -> 3120, numDeletionVectorsRemoved -> 1, minFileSize -> 3120, numAddedFiles -> 1, maxFileSize -> 3120, p75FileSize -> 3120, p50FileSize -> 3120, numAddedBytes -> 3120}                                                                                       |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|14     |2025-06-19 07:02:17    |3359264194789707|azuser3558_mml.local@techademy.com|DELETE   |{predicate -> [\"(ProgressPercent#21471 = 0)\"]}                                |NULL|{3428140736495296}|0611-041524-ifuhl15z|13         |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 163, numDeletionVectorsUpdated -> 0, numDeletedRows -> 0, scanTimeMs -> 162, numAddedFiles -> 0, numAddedBytes -> 0, rewriteTimeMs -> 0}      |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|13     |2025-06-19 07:02:16    |3359264194789707|azuser3558_mml.local@techademy.com|UPDATE   |{predicate -> [\"(CourseName#21467 = Python Basics)\"]}                         |NULL|{3428140736495296}|0611-041524-ifuhl15z|12         |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 1, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 1163, numDeletionVectorsUpdated -> 0, scanTimeMs -> 502, numAddedFiles -> 1, numUpdatedRows -> 2, numAddedBytes -> 2891, rewriteTimeMs -> 660}|NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|12     |2025-06-19 07:02:13    |3359264194789707|azuser3558_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                  |NULL|{3428140736495296}|0611-041524-ifuhl15z|11         |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 3112}                                                                                                                                                                                                                                                               |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|11     |2025-06-19 07:00:27    |3359264194789707|azuser3558_mml.local@techademy.com|OPTIMIZE |{predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0}|NULL|{3428140736495296}|0611-041524-ifuhl15z|10         |SnapshotIsolation|false        |{numRemovedFiles -> 2, numRemovedBytes -> 6003, p25FileSize -> 3120, numDeletionVectorsRemoved -> 1, minFileSize -> 3120, numAddedFiles -> 1, maxFileSize -> 3120, p75FileSize -> 3120, p50FileSize -> 3120, numAddedBytes -> 3120}                                                                                       |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|10     |2025-06-19 07:00:25.001|3359264194789707|azuser3558_mml.local@techademy.com|DELETE   |{predicate -> [\"(ProgressPercent#17959 = 0)\"]}                                |NULL|{3428140736495296}|0611-041524-ifuhl15z|9          |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 167, numDeletionVectorsUpdated -> 0, numDeletedRows -> 0, scanTimeMs -> 167, numAddedFiles -> 0, numAddedBytes -> 0, rewriteTimeMs -> 0}      |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|9      |2025-06-19 07:00:25    |3359264194789707|azuser3558_mml.local@techademy.com|UPDATE   |{predicate -> [\"(CourseName#17955 = Python Basics)\"]}                         |NULL|{3428140736495296}|0611-041524-ifuhl15z|8          |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 1, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 1070, numDeletionVectorsUpdated -> 0, scanTimeMs -> 456, numAddedFiles -> 1, numUpdatedRows -> 2, numAddedBytes -> 2891, rewriteTimeMs -> 614}|NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|8      |2025-06-19 07:00:22    |3359264194789707|azuser3558_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                  |NULL|{3428140736495296}|0611-041524-ifuhl15z|7          |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 3112}                                                                                                                                                                                                                                                               |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|7      |2025-06-19 06:42:37    |3359264194789707|azuser3558_mml.local@techademy.com|OPTIMIZE |{predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0}|NULL|{3428140736495296}|0611-041524-ifuhl15z|6          |SnapshotIsolation|false        |{numRemovedFiles -> 2, numRemovedBytes -> 6003, p25FileSize -> 3120, numDeletionVectorsRemoved -> 1, minFileSize -> 3120, numAddedFiles -> 1, maxFileSize -> 3120, p75FileSize -> 3120, p50FileSize -> 3120, numAddedBytes -> 3120}                                                                                       |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|6      |2025-06-19 06:42:35    |3359264194789707|azuser3558_mml.local@techademy.com|DELETE   |{predicate -> [\"(ProgressPercent#12927 = 0)\"]}                                |NULL|{3428140736495296}|0611-041524-ifuhl15z|5          |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 249, numDeletionVectorsUpdated -> 0, numDeletedRows -> 0, scanTimeMs -> 249, numAddedFiles -> 0, numAddedBytes -> 0, rewriteTimeMs -> 0}      |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|5      |2025-06-19 06:42:34    |3359264194789707|azuser3558_mml.local@techademy.com|UPDATE   |{predicate -> [\"(CourseName#12923 = Python Basics)\"]}                         |NULL|{3428140736495296}|0611-041524-ifuhl15z|4          |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 1, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 1183, numDeletionVectorsUpdated -> 0, scanTimeMs -> 490, numAddedFiles -> 1, numUpdatedRows -> 2, numAddedBytes -> 2891, rewriteTimeMs -> 687}|NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|4      |2025-06-19 06:42:31    |3359264194789707|azuser3558_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                  |NULL|{3428140736495296}|0611-041524-ifuhl15z|3          |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 3112}                                                                                                                                                                                                                                                               |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|3      |2025-06-19 06:26:20    |3359264194789707|azuser3558_mml.local@techademy.com|OPTIMIZE |{predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0}|NULL|{3428140736495296}|0611-041524-ifuhl15z|1          |SnapshotIsolation|false        |{numRemovedFiles -> 2, numRemovedBytes -> 6003, p25FileSize -> 3120, numDeletionVectorsRemoved -> 1, conflictDetectionTimeMs -> 16, minFileSize -> 3120, numAddedFiles -> 1, maxFileSize -> 3120, p75FileSize -> 3120, p50FileSize -> 3120, numAddedBytes -> 3120}                                                        |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n+-------+-----------------------+----------------+----------------------------------+---------+------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\nonly showing top 20 rows\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EnrollID</th><th>UserID</th><th>CourseID</th><th>CourseName</th><th>Category</th><th>EnrollDate</th><th>CompletionDate</th><th>ProgressPercent</th><th>Rating</th><th>DaysToComplete</th><th>IsCompleted</th></tr></thead><tbody><tr><td>E002</td><td>U002</td><td>C002</td><td>Excel for Finance</td><td>Productivity</td><td>2024-04-02</td><td>null</td><td>45</td><td>0</td><td>null</td><td>0</td></tr><tr><td>E003</td><td>U001</td><td>C003</td><td>ML with PySpark</td><td>Data Science</td><td>2024-04-03</td><td>null</td><td>30</td><td>0</td><td>null</td><td>0</td></tr><tr><td>E005</td><td>U004</td><td>C004</td><td>Digital Marketing</td><td>Marketing</td><td>2024-04-05</td><td>2024-04-16</td><td>100</td><td>4</td><td>11</td><td>1</td></tr><tr><td>E001</td><td>U001</td><td>C001</td><td>Python Basics</td><td>Programming</td><td>2024-04-01</td><td>2024-04-10</td><td>100</td><td>5</td><td>9</td><td>1</td></tr><tr><td>E004</td><td>U003</td><td>C001</td><td>Python Basics</td><td>Programming</td><td>2024-04-04</td><td>2024-04-20</td><td>100</td><td>5</td><td>16</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "E002",
         "U002",
         "C002",
         "Excel for Finance",
         "Productivity",
         "2024-04-02",
         null,
         45,
         0,
         null,
         0
        ],
        [
         "E003",
         "U001",
         "C003",
         "ML with PySpark",
         "Data Science",
         "2024-04-03",
         null,
         30,
         0,
         null,
         0
        ],
        [
         "E005",
         "U004",
         "C004",
         "Digital Marketing",
         "Marketing",
         "2024-04-05",
         "2024-04-16",
         100,
         4,
         11,
         1
        ],
        [
         "E001",
         "U001",
         "C001",
         "Python Basics",
         "Programming",
         "2024-04-01",
         "2024-04-10",
         100,
         5,
         9,
         1
        ],
        [
         "E004",
         "U003",
         "C001",
         "Python Basics",
         "Programming",
         "2024-04-04",
         "2024-04-20",
         100,
         5,
         16,
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EnrollID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "UserID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CourseID",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CourseName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "EnrollDate",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "CompletionDate",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "ProgressPercent",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "Rating",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "DaysToComplete",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "IsCompleted",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Delta Lake Practice\n",
    "# Save as Delta Table enrollments_delta\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/data/enrollments_delta\")\n",
    "\n",
    "# Load the Delta table\n",
    "from delta.tables import DeltaTable\n",
    "delta_df = DeltaTable.forPath(spark, \"/mnt/data/enrollments_delta\")\n",
    "\n",
    "# Update: Set all ratings to 5 where Course = 'Python Basics'\n",
    "delta_df.update(\n",
    "    condition=col(\"CourseName\") == \"Python Basics\",set={\"Rating\": expr(\"5\")}\n",
    ")\n",
    "\n",
    "# Delete: All rows where ProgressPercent = 0\n",
    "delta_df.delete(condition=col(\"ProgressPercent\") == 0)\n",
    "\n",
    "# Show DESCRIBE HISTORY\n",
    "spark.sql(\"DESCRIBE HISTORY delta.`/mnt/data/enrollments_delta`\").show(truncate=False)\n",
    "delta_df.toDF().display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "280bc7b7-5c9f-4548-9584-5782e027ff70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+\n|CourseID|Enrollments|CourseRank|\n+--------+-----------+----------+\n|    C001|          2|         1|\n|    C004|          1|         2|\n|    C003|          1|         2|\n|    C002|          1|         2|\n+--------+-----------+----------+\n\n+------+--------+-----------------+----------+------------+---------------+\n|UserID|CourseID|       CourseName|EnrollDate|NextCourseID| NextCourseName|\n+------+--------+-----------------+----------+------------+---------------+\n|  U001|    C001|    Python Basics|2024-04-01|        C003|ML with PySpark|\n|  U001|    C003|  ML with PySpark|2024-04-03|        NULL|           NULL|\n|  U002|    C002|Excel for Finance|2024-04-02|        NULL|           NULL|\n|  U003|    C001|    Python Basics|2024-04-04|        NULL|           NULL|\n|  U004|    C004|Digital Marketing|2024-04-05|        NULL|           NULL|\n+------+--------+-----------------+----------+------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 7. Window Functions\n",
    "# Use dense_rank() to rank courses by number of enrollments\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import dense_rank, count\n",
    "\n",
    "course_counts = df.groupBy(\"CourseID\").agg(count(\"*\").alias(\"Enrollments\"))\n",
    "rank_window = Window.orderBy(col(\"Enrollments\").desc())\n",
    "\n",
    "rank_courses = course_counts.withColumn(\"CourseRank\", dense_rank().over(rank_window))\n",
    "rank_courses.show()\n",
    "\n",
    "# lead() to find next course by each user (sorted by EnrollDate)\n",
    "from pyspark.sql.functions import lead\n",
    "\n",
    "next_course_window = Window.partitionBy(\"UserID\").orderBy(\"EnrollDate\")\n",
    "\n",
    "next_course_df=df.withColumn(\"NextCourseID\", lead(\"CourseID\").over(next_course_window)) \\\n",
    "                 .withColumn(\"NextCourseName\", lead(\"CourseName\").over(next_course_window))\n",
    "\n",
    "next_course_df.select(\"UserID\", \"CourseID\", \"CourseName\", \"EnrollDate\", \"NextCourseID\", \"NextCourseName\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee8bf637-2685-40eb-9995-f866d4f55fd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+\n|EnrollDate|TotalEnrollments|\n+----------+----------------+\n|2024-04-01|               1|\n|2024-04-02|               1|\n|2024-04-03|               1|\n|2024-04-04|               1|\n|2024-04-05|               1|\n+----------+----------------+\n\n+------------+---------+\n|    Category|AvgRating|\n+------------+---------+\n| Programming|      4.5|\n|Productivity|      0.0|\n|   Marketing|      4.0|\n|Data Science|      0.0|\n+------------+---------+\n\n+--------+-----------------+---------+----------------+\n|CourseID|       CourseName|AvgRating|TotalEnrollments|\n+--------+-----------------+---------+----------------+\n|    C001|    Python Basics|      4.5|               2|\n|    C004|Digital Marketing|      4.0|               1|\n|    C002|Excel for Finance|      0.0|               1|\n+--------+-----------------+---------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 8\n",
    "# SQL Logic for Dashboard Views\n",
    "# Create views:\n",
    "df.createOrReplaceTempView(\"enrollments\")\n",
    "\n",
    "# daily_enrollments\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW daily_enrollments AS\n",
    "select EnrollDate, COUNT(*) AS TotalEnrollments\n",
    "from enrollments GROUP BY EnrollDate\n",
    "ORDER BY EnrollDate\n",
    "\"\"\")\n",
    "spark.sql(\"SELECT * FROM daily_enrollments\").show()\n",
    "\n",
    "# category_performance (avg rating by category)\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW category_performance AS\n",
    "select Category, ROUND(AVG(Rating), 2) AS AvgRating\n",
    "from enrollments where Rating IS NOT NULL\n",
    "GROUP BY Category;\n",
    "\"\"\")\n",
    "spark.sql(\"SELECT * FROM category_performance\").show()\n",
    "\n",
    "# top_3_courses\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW top_3_courses AS\n",
    "select CourseID, CourseName, ROUND(AVG(Rating), 2) AS AvgRating, COUNT(*) AS TotalEnrollments\n",
    "from enrollments\n",
    "GROUP BY CourseID, CourseName\n",
    "ORDER BY AvgRating DESC, TotalEnrollments DESC\n",
    "LIMIT 3;\n",
    "\"\"\")\n",
    "spark.sql(\"SELECT * FROM top_3_courses\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec0696ec-cb68-42b9-80a2-24516b15b998",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+----------------+----------------------------------+---------+------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\n|version|timestamp              |userId          |userName                          |operation|operationParameters                                                           |job |notebook          |clusterId           |readVersion|isolationLevel   |isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                          |userMetadata|engineInfo                                |\n+-------+-----------------------+----------------+----------------------------------+---------+------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\n|11     |2025-06-19 07:00:27    |3359264194789707|azuser3558_mml.local@techademy.com|OPTIMIZE |{predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0}|NULL|{3428140736495296}|0611-041524-ifuhl15z|10         |SnapshotIsolation|false        |{numRemovedFiles -> 2, numRemovedBytes -> 6003, p25FileSize -> 3120, numDeletionVectorsRemoved -> 1, minFileSize -> 3120, numAddedFiles -> 1, maxFileSize -> 3120, p75FileSize -> 3120, p50FileSize -> 3120, numAddedBytes -> 3120}                                                                                       |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|10     |2025-06-19 07:00:25.001|3359264194789707|azuser3558_mml.local@techademy.com|DELETE   |{predicate -> [\"(ProgressPercent#17959 = 0)\"]}                                |NULL|{3428140736495296}|0611-041524-ifuhl15z|9          |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 167, numDeletionVectorsUpdated -> 0, numDeletedRows -> 0, scanTimeMs -> 167, numAddedFiles -> 0, numAddedBytes -> 0, rewriteTimeMs -> 0}      |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|9      |2025-06-19 07:00:25    |3359264194789707|azuser3558_mml.local@techademy.com|UPDATE   |{predicate -> [\"(CourseName#17955 = Python Basics)\"]}                         |NULL|{3428140736495296}|0611-041524-ifuhl15z|8          |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 1, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 1070, numDeletionVectorsUpdated -> 0, scanTimeMs -> 456, numAddedFiles -> 1, numUpdatedRows -> 2, numAddedBytes -> 2891, rewriteTimeMs -> 614}|NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|8      |2025-06-19 07:00:22    |3359264194789707|azuser3558_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                  |NULL|{3428140736495296}|0611-041524-ifuhl15z|7          |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 3112}                                                                                                                                                                                                                                                               |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|7      |2025-06-19 06:42:37    |3359264194789707|azuser3558_mml.local@techademy.com|OPTIMIZE |{predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0}|NULL|{3428140736495296}|0611-041524-ifuhl15z|6          |SnapshotIsolation|false        |{numRemovedFiles -> 2, numRemovedBytes -> 6003, p25FileSize -> 3120, numDeletionVectorsRemoved -> 1, minFileSize -> 3120, numAddedFiles -> 1, maxFileSize -> 3120, p75FileSize -> 3120, p50FileSize -> 3120, numAddedBytes -> 3120}                                                                                       |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|6      |2025-06-19 06:42:35    |3359264194789707|azuser3558_mml.local@techademy.com|DELETE   |{predicate -> [\"(ProgressPercent#12927 = 0)\"]}                                |NULL|{3428140736495296}|0611-041524-ifuhl15z|5          |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 249, numDeletionVectorsUpdated -> 0, numDeletedRows -> 0, scanTimeMs -> 249, numAddedFiles -> 0, numAddedBytes -> 0, rewriteTimeMs -> 0}      |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|5      |2025-06-19 06:42:34    |3359264194789707|azuser3558_mml.local@techademy.com|UPDATE   |{predicate -> [\"(CourseName#12923 = Python Basics)\"]}                         |NULL|{3428140736495296}|0611-041524-ifuhl15z|4          |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 1, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 1183, numDeletionVectorsUpdated -> 0, scanTimeMs -> 490, numAddedFiles -> 1, numUpdatedRows -> 2, numAddedBytes -> 2891, rewriteTimeMs -> 687}|NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|4      |2025-06-19 06:42:31    |3359264194789707|azuser3558_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                  |NULL|{3428140736495296}|0611-041524-ifuhl15z|3          |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 3112}                                                                                                                                                                                                                                                               |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|3      |2025-06-19 06:26:20    |3359264194789707|azuser3558_mml.local@techademy.com|OPTIMIZE |{predicate -> [], auto -> true, clusterBy -> [], zOrderBy -> [], batchId -> 0}|NULL|{3428140736495296}|0611-041524-ifuhl15z|1          |SnapshotIsolation|false        |{numRemovedFiles -> 2, numRemovedBytes -> 6003, p25FileSize -> 3120, numDeletionVectorsRemoved -> 1, conflictDetectionTimeMs -> 16, minFileSize -> 3120, numAddedFiles -> 1, maxFileSize -> 3120, p75FileSize -> 3120, p50FileSize -> 3120, numAddedBytes -> 3120}                                                        |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|2      |2025-06-19 06:26:18    |3359264194789707|azuser3558_mml.local@techademy.com|DELETE   |{predicate -> [\"(ProgressPercent#9891 = 0)\"]}                                 |NULL|{3428140736495296}|0611-041524-ifuhl15z|1          |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 0, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 176, numDeletionVectorsUpdated -> 0, numDeletedRows -> 0, scanTimeMs -> 176, numAddedFiles -> 0, numAddedBytes -> 0, rewriteTimeMs -> 0}      |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|1      |2025-06-19 06:26:17    |3359264194789707|azuser3558_mml.local@techademy.com|UPDATE   |{predicate -> [\"(CourseName#9887 = Python Basics)\"]}                          |NULL|{3428140736495296}|0611-041524-ifuhl15z|0          |WriteSerializable|false        |{numRemovedFiles -> 0, numRemovedBytes -> 0, numCopiedRows -> 0, numDeletionVectorsAdded -> 1, numDeletionVectorsRemoved -> 0, numAddedChangeFiles -> 0, executionTimeMs -> 1297, numDeletionVectorsUpdated -> 0, scanTimeMs -> 543, numAddedFiles -> 1, numUpdatedRows -> 2, numAddedBytes -> 2891, rewriteTimeMs -> 752}|NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n|0      |2025-06-19 06:26:15    |3359264194789707|azuser3558_mml.local@techademy.com|WRITE    |{mode -> Overwrite, statsOnLoad -> false, partitionBy -> []}                  |NULL|{3428140736495296}|0611-041524-ifuhl15z|NULL       |WriteSerializable|false        |{numFiles -> 1, numOutputRows -> 5, numOutputBytes -> 3112}                                                                                                                                                                                                                                                               |NULL        |Databricks-Runtime/15.4.x-photon-scala2.12|\n+-------+-----------------------+----------------+----------------------------------+---------+------------------------------------------------------------------------------+----+------------------+--------------------+-----------+-----------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+------------------------------------------+\n\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|IsCompleted|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     4|             9|          1|\n|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|     0|          NULL|          0|\n|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|     0|          NULL|          0|\n|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|            16|          1|\n|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|            11|          1|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n|EnrollID|UserID|CourseID|       CourseName|    Category|EnrollDate|CompletionDate|ProgressPercent|Rating|DaysToComplete|IsCompleted|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n|    E001|  U001|    C001|    Python Basics| Programming|2024-04-01|    2024-04-10|            100|     5|             9|          1|\n|    E004|  U003|    C001|    Python Basics| Programming|2024-04-04|    2024-04-20|            100|     5|            16|          1|\n|    E002|  U002|    C002|Excel for Finance|Productivity|2024-04-02|          NULL|             45|     0|          NULL|          0|\n|    E003|  U001|    C003|  ML with PySpark|Data Science|2024-04-03|          NULL|             30|     0|          NULL|          0|\n|    E005|  U004|    C004|Digital Marketing|   Marketing|2024-04-05|    2024-04-16|            100|     4|            11|          1|\n+--------+------+--------+-----------------+------------+----------+--------------+---------------+------+--------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 9. Time Travel\n",
    "# View previous version before update/delete\n",
    "path = \"/mnt/data/enrollments_delta\"\n",
    "spark.sql(f\"DESCRIBE HISTORY delta.`{path}`\").show(truncate=False)\n",
    "\n",
    "# Use VERSION AS OF \n",
    "version_df = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(path)\n",
    "version_df.show()\n",
    "\n",
    "# Use TIMESTAMP AS OF\n",
    "timestamp_df = spark.read.format(\"delta\").option(\"timestampAsOf\", \"2025-06-19T06:42:37\").load(path)\n",
    "timestamp_df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dea0252c-b658-43ed-97c8-632ecd984188",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Export Reporting\n",
    "# Write to JSON, partitioned by Category\n",
    "\n",
    "df.write.partitionBy(\"Category\").mode(\"overwrite\").json(\"/mnt/data/enrollments_by_category\")\n",
    "\n",
    "# Create summary DataFrame:\n",
    "# CourseName, TotalEnrollments, AvgRating, AvgProgress\n",
    "from pyspark.sql.functions import count, avg, round\n",
    "\n",
    "summary_df = df.groupBy(\"CourseName\").agg(\n",
    "    count(\"*\").alias(\"TotalEnrollments\"),\n",
    "    round(avg(\"Rating\"), 2).alias(\"AvgRating\"),\n",
    "    round(avg(\"ProgressPercent\"), 2).alias(\"AvgProgress\")\n",
    ")\n",
    "\n",
    "# Save as Parquet\n",
    "summary_df.write.mode(\"overwrite\").parquet(\"/mnt/data/course_summary_parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Set_2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}