{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "with open(\"customers.csv\", \"w\") as f:\n",
        "    f.write(\"\"\"CustomerID,Name,Email,City,SignupDate\n",
        "101,Ali,ali@gmail.com,Mumbai,2022-05-10\n",
        "102,Neha,neha@yahoo.com,Delhi,2023-01-15\n",
        "103,Ravi,ravi@hotmail.com,Bangalore,2021-11-01\n",
        "104,Sneha,sneha@outlook.com,Hyderabad,2020-07-22\n",
        "105,Amit,amit@gmail.com,Chennai,2023-03-10\"\"\")\n",
        "\n",
        "with open(\"orders.csv\", \"w\") as f:\n",
        "    f.write(\"\"\"OrderID,CustomerID,Product,Category,Quantity,Price,OrderDate\n",
        "1,101,Laptop,Electronics,2,50000.0,2024-01-10\n",
        "2,101,Mouse,Electronics,1,1200.0,2024-01-15\n",
        "3,102,Tablet,Electronics,1,20000.0,2024-02-01\n",
        "4,103,Bookshelf,Furniture,1,3500.0,2024-02-10\n",
        "5,104,Mixer,Appliances,1,5000.0,2024-02-15\n",
        "6,105,Notebook,Stationery,5,500.0,2024-03-01\n",
        "7,102,Phone,Electronics,1,30000.0,2024-03-02\"\"\")\n"
      ],
      "metadata": {
        "id": "s_NvSa8K-f1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzEdf-ja97nL",
        "outputId": "81272230-e534-43c1-c078-dc44997c6e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers Schema:\n",
            "root\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Email: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- SignupDate: date (nullable = true)\n",
            "\n",
            "Orders Schema:\n",
            "root\n",
            " |-- OrderID: integer (nullable = true)\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- Price: double (nullable = true)\n",
            " |-- OrderDate: date (nullable = true)\n",
            "\n",
            "\n",
            "Total Customers: 5\n",
            "Total Orders: 7\n",
            "\n",
            "Distinct Cities:\n",
            "+---------+\n",
            "|     City|\n",
            "+---------+\n",
            "|Bangalore|\n",
            "|  Chennai|\n",
            "|   Mumbai|\n",
            "|    Delhi|\n",
            "|Hyderabad|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CustomerOrders\").getOrCreate()\n",
        "\n",
        "# Load both CSV files with schema inference\n",
        "customers_df = spark.read.csv(\"customers.csv\", header=True, inferSchema=True)\n",
        "orders_df = spark.read.csv(\"orders.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# List all columns and data types\n",
        "print(\"Customers Schema:\")\n",
        "customers_df.printSchema()\n",
        "\n",
        "print(\"Orders Schema:\")\n",
        "orders_df.printSchema()\n",
        "\n",
        "# Count total number of customers and orders\n",
        "\n",
        "print(\"\\nTotal Customers:\", customers_df.count())\n",
        "print(\"Total Orders:\", orders_df.count())\n",
        "\n",
        "# Show distinct cities\n",
        "print(\"\\nDistinct Cities:\")\n",
        "customers_df.select(\"City\").distinct().show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. DataFrame Transformations\n",
        "from pyspark.sql.functions import year\n",
        "\n",
        "# Add a column TotalAmount = Price * Quantity\n",
        "orders_df = orders_df.withColumn(\"TotalAmount\", col(\"Price\") * col(\"Quantity\"))\n",
        "\n",
        "# Create a new column OrderYear from OrderDate\n",
        "orders_df = orders_df.withColumn(\"OrderYear\", year(col(\"OrderDate\")))\n",
        "orders_df.show()\n",
        "\n",
        "# Filter orders with TotalAmount > 10,000\n",
        "filter_orders_df = orders_df.filter(col(\"TotalAmount\") > 10000)\n",
        "print(\"High-Value Orders:\")\n",
        "filter_orders_df.show()\n",
        "\n",
        "# Drop the Email column from customers\n",
        "customersDf = customers_df.drop(\"Email\")\n",
        "print(\"Customers without Email:\")\n",
        "customersDf.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsE3F57T988n",
        "outputId": "96b944a4-2326-4a0e-f99e-613e8531ad86"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "\n",
            "High-Value Orders:\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "|      1|       101| Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|\n",
            "|      3|       102| Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|\n",
            "|      7|       102|  Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "\n",
            "Customers without Email:\n",
            "+----------+-----+---------+----------+\n",
            "|CustomerID| Name|     City|SignupDate|\n",
            "+----------+-----+---------+----------+\n",
            "|       101|  Ali|   Mumbai|2022-05-10|\n",
            "|       102| Neha|    Delhi|2023-01-15|\n",
            "|       103| Ravi|Bangalore|2021-11-01|\n",
            "|       104|Sneha|Hyderabad|2020-07-22|\n",
            "|       105| Amit|  Chennai|2023-03-10|\n",
            "+----------+-----+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Handling Nulls & Conditionals\n",
        "from pyspark.sql.functions import when, col, lit\n",
        "\n",
        "# Simulate a null in City and fill with \"Unknown\"\n",
        "customers_city = customers_df.withColumn(\n",
        "    \"City\",when(col(\"SignupDate\") < \"2022-05-10\", lit(None)).otherwise(col(\"City\"))\n",
        ")\n",
        "customers = customers_city.fillna({\"City\": \"Unknown\"})\n",
        "customers.show()\n",
        "\n",
        "# Label customers as “Loyal” if SignupDate < 2022, else “New”\n",
        "customers_label = customers.withColumn(\n",
        "    \"CustomerType\", when(col(\"SignupDate\") < \"2022-01-01\", \"Loyal\").otherwise(\"New\")\n",
        ")\n",
        "customers_label.show()\n",
        "\n",
        "# Create OrderType column: \"Low\" if TotalAmount < 5000, else \"High\"\n",
        "# orders_df = orders_df.withColumn(\"TotalAmount\", col(\"Price\") * col(\"Quantity\"))\n",
        "\n",
        "orders_type = orders_df.withColumn(\n",
        "    \"OrderType\",when(col(\"TotalAmount\") < 5000, \"Low\").otherwise(\"High\")\n",
        ")\n",
        "orders_type.show()\n"
      ],
      "metadata": {
        "id": "QUCsPDcK_pT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d804d92-9e04-46fe-cea1-b9ff5ec40ef4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----------------+-------+----------+\n",
            "|CustomerID| Name|            Email|   City|SignupDate|\n",
            "+----------+-----+-----------------+-------+----------+\n",
            "|       101|  Ali|    ali@gmail.com| Mumbai|2022-05-10|\n",
            "|       102| Neha|   neha@yahoo.com|  Delhi|2023-01-15|\n",
            "|       103| Ravi| ravi@hotmail.com|Unknown|2021-11-01|\n",
            "|       104|Sneha|sneha@outlook.com|Unknown|2020-07-22|\n",
            "|       105| Amit|   amit@gmail.com|Chennai|2023-03-10|\n",
            "+----------+-----+-----------------+-------+----------+\n",
            "\n",
            "+----------+-----+-----------------+-------+----------+------------+\n",
            "|CustomerID| Name|            Email|   City|SignupDate|CustomerType|\n",
            "+----------+-----+-----------------+-------+----------+------------+\n",
            "|       101|  Ali|    ali@gmail.com| Mumbai|2022-05-10|         New|\n",
            "|       102| Neha|   neha@yahoo.com|  Delhi|2023-01-15|         New|\n",
            "|       103| Ravi| ravi@hotmail.com|Unknown|2021-11-01|       Loyal|\n",
            "|       104|Sneha|sneha@outlook.com|Unknown|2020-07-22|       Loyal|\n",
            "|       105| Amit|   amit@gmail.com|Chennai|2023-03-10|         New|\n",
            "+----------+-----+-----------------+-------+----------+------------+\n",
            "\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderType|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|     High|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|      Low|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|     High|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|      Low|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|     High|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|      Low|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|     High|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4.Joins & Aggregations\n",
        "\n",
        "# Join customers and orders on CustomerID\n",
        "joined_df = customers_df.join(orders_df, on=\"CustomerID\", how=\"inner\")\n",
        "\n",
        "# Total orders and revenue per city\n",
        "\n",
        "order = joined_df.groupBy(\"City\").agg(\n",
        "    {\"OrderID\": \"count\", \"TotalAmount\": \"sum\"}\n",
        ").withColumnRenamed(\"count(OrderID)\", \"TotalOrders\") \\\n",
        " .withColumnRenamed(\"sum(TotalAmount)\", \"TotalRevenue\")\n",
        "order.show()\n",
        "\n",
        "# Show top 3 customers by total spend\n",
        "\n",
        "top_customers = joined_df.groupBy(\"CustomerID\", \"Name\").agg(\n",
        "    {\"TotalAmount\": \"sum\"}\n",
        ").withColumnRenamed(\"sum(TotalAmount)\", \"TotalSpend\") \\\n",
        " .orderBy(col(\"TotalSpend\").desc()) \\\n",
        " .limit(3)\n",
        "top_customers.show()\n",
        "\n",
        "# Count how many products each category has sold\n",
        "\n",
        "category_sales = orders_df.groupBy(\"Category\").agg(\n",
        "    {\"Quantity\": \"sum\"}\n",
        ").withColumnRenamed(\"sum(Quantity)\", \"ProductsSold\")\n",
        "category_sales.show()"
      ],
      "metadata": {
        "id": "7exYbUe5_qHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad524b5-547e-4143-c00a-8caaecc1ce77"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+-----------+\n",
            "|     City|TotalRevenue|TotalOrders|\n",
            "+---------+------------+-----------+\n",
            "|Bangalore|      3500.0|          1|\n",
            "|  Chennai|      2500.0|          1|\n",
            "|   Mumbai|    101200.0|          2|\n",
            "|    Delhi|     50000.0|          2|\n",
            "|Hyderabad|      5000.0|          1|\n",
            "+---------+------------+-----------+\n",
            "\n",
            "+----------+-----+----------+\n",
            "|CustomerID| Name|TotalSpend|\n",
            "+----------+-----+----------+\n",
            "|       101|  Ali|  101200.0|\n",
            "|       102| Neha|   50000.0|\n",
            "|       104|Sneha|    5000.0|\n",
            "+----------+-----+----------+\n",
            "\n",
            "+-----------+------------+\n",
            "|   Category|ProductsSold|\n",
            "+-----------+------------+\n",
            "| Stationery|           5|\n",
            "|Electronics|           5|\n",
            "|  Furniture|           1|\n",
            "| Appliances|           1|\n",
            "+-----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Spark SQL Tasks\n",
        "# Create database and switch to it\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS sales\")\n",
        "spark.sql(\"USE sales\")\n",
        "\n",
        "# Save both datasets as tables in the sales database\n",
        "customers_df.write.mode(\"overwrite\").saveAsTable(\"sales.customers\")\n",
        "orders_df.write.mode(\"overwrite\").saveAsTable(\"sales.orders\")\n"
      ],
      "metadata": {
        "id": "gQQBQJm7_yqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5db020-5a66-4b41-8e44-ca33a24bce50"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----------------+---------+----------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "|       101|  Ali|    ali@gmail.com|   Mumbai|2022-05-10|\n",
            "|       102| Neha|   neha@yahoo.com|    Delhi|2023-01-15|\n",
            "|       103| Ravi| ravi@hotmail.com|Bangalore|2021-11-01|\n",
            "|       104|Sneha|sneha@outlook.com|Hyderabad|2020-07-22|\n",
            "|       105| Amit|   amit@gmail.com|  Chennai|2023-03-10|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all orders by customers from “Delhi”\n",
        "spark.sql(\"\"\"\n",
        "SELECT o.*\n",
        "FROM orders o\n",
        "JOIN customers c ON o.CustomerID = c.CustomerID\n",
        "WHERE c.City = 'Delhi'\n",
        "\"\"\").show()\n",
        "\n",
        "# Find average order value in each category\n",
        "spark.sql(\"\"\"\n",
        "SELECT Category, ROUND(AVG(TotalAmount), 2) AS AvgOrderValue\n",
        "FROM orders\n",
        "GROUP BY Category\n",
        "\"\"\").show()\n",
        "\n",
        "# Create a view `monthly_orders` with month-wise total amount\n",
        "# Create a TEMPORARY view instead of a persistent one\n",
        "spark.sql(\"\"\"\n",
        "CREATE OR REPLACE TEMP VIEW monthly_orders AS\n",
        "SELECT\n",
        "    DATE_FORMAT(OrderDate, 'yyyy-MM') AS Month,\n",
        "    SUM(TotalAmount) AS TotalMonthlyAmount\n",
        "FROM orders\n",
        "GROUP BY DATE_FORMAT(OrderDate, 'yyyy-MM')\n",
        "\"\"\")\n",
        "\n",
        "spark.sql(\"SELECT * FROM monthly_orders\").show()\n"
      ],
      "metadata": {
        "id": "JQD2RWPk_zYZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6a92ac-41ab-4529-9890-5cbfed151b78"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "|      3|       102| Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|\n",
            "|      7|       102|  Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "\n",
            "+-----------+-------------+\n",
            "|   Category|AvgOrderValue|\n",
            "+-----------+-------------+\n",
            "| Stationery|       2500.0|\n",
            "|Electronics|      37800.0|\n",
            "|  Furniture|       3500.0|\n",
            "| Appliances|       5000.0|\n",
            "+-----------+-------------+\n",
            "\n",
            "+-------+------------------+\n",
            "|  Month|TotalMonthlyAmount|\n",
            "+-------+------------------+\n",
            "|2024-02|           28500.0|\n",
            "|2024-03|           32500.0|\n",
            "|2024-01|          101200.0|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6. String & Date Functions\n",
        "\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "#Mask emails using regex (e.g., a***@gmail.com ).\n",
        "customers_email = customers_df.withColumn(\n",
        "    \"MaskedEmail\",regexp_replace(\"Email\", r\"(^.).*(@.*)\", r\"\\1***\\2\")\n",
        ")\n",
        "customers_email.show()\n",
        "\n",
        "# Concatenate Name and City as “Name from City”\n",
        "\n",
        "from pyspark.sql.functions import concat_ws, col\n",
        "customers = customers.withColumn(\n",
        "    \"NameFromCity\",concat_ws(\" from \", col(\"Name\"), col(\"City\"))\n",
        ")\n",
        "customers.show()\n",
        "\n",
        "# Use datediff() to calculate customer age in days.\n",
        "\n",
        "from pyspark.sql.functions import datediff, current_date, to_date\n",
        "\n",
        "customers = customers.withColumn(\n",
        "    \"CustomerAgeDays\",datediff(current_date(), to_date(col(\"SignupDate\")))\n",
        ")\n",
        "customers.show()\n",
        "\n",
        "# Extract month name from OrderDate\n",
        "from pyspark.sql.functions import date_format, to_date\n",
        "\n",
        "orders_with_month = orders_df.withColumn(\n",
        "    \"OrderMonthName\",\n",
        "    date_format(to_date(col(\"OrderDate\")), \"MMMM\")\n",
        ")\n",
        "\n",
        "orders_with_month.select(\"OrderId\",\"OrderDate\", \"OrderMonthName\").show()"
      ],
      "metadata": {
        "id": "TBqViR7A_1uT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98f1ad6-eb28-4496-bf6b-6951b9a360e4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-----------------+---------+----------+-----------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|MaskedEmail|\n",
            "+----------+-----+-----------------+---------+----------+-----------+\n",
            "|       101|  Ali|    ali@gmail.com|   Mumbai|2022-05-10|      1***2|\n",
            "|       102| Neha|   neha@yahoo.com|    Delhi|2023-01-15|      1***2|\n",
            "|       103| Ravi| ravi@hotmail.com|Bangalore|2021-11-01|      1***2|\n",
            "|       104|Sneha|sneha@outlook.com|Hyderabad|2020-07-22|      1***2|\n",
            "|       105| Amit|   amit@gmail.com|  Chennai|2023-03-10|      1***2|\n",
            "+----------+-----+-----------------+---------+----------+-----------+\n",
            "\n",
            "+----------+-----+-----------------+-------+----------+------------------+---------------+\n",
            "|CustomerID| Name|            Email|   City|SignupDate|      NameFromCity|CustomerAgeDays|\n",
            "+----------+-----+-----------------+-------+----------+------------------+---------------+\n",
            "|       101|  Ali|    ali@gmail.com| Mumbai|2022-05-10|   Ali from Mumbai|           1126|\n",
            "|       102| Neha|   neha@yahoo.com|  Delhi|2023-01-15|   Neha from Delhi|            876|\n",
            "|       103| Ravi| ravi@hotmail.com|Unknown|2021-11-01| Ravi from Unknown|           1316|\n",
            "|       104|Sneha|sneha@outlook.com|Unknown|2020-07-22|Sneha from Unknown|           1783|\n",
            "|       105| Amit|   amit@gmail.com|Chennai|2023-03-10| Amit from Chennai|            822|\n",
            "+----------+-----+-----------------+-------+----------+------------------+---------------+\n",
            "\n",
            "+----------+-----+-----------------+-------+----------+------------------+---------------+\n",
            "|CustomerID| Name|            Email|   City|SignupDate|      NameFromCity|CustomerAgeDays|\n",
            "+----------+-----+-----------------+-------+----------+------------------+---------------+\n",
            "|       101|  Ali|    ali@gmail.com| Mumbai|2022-05-10|   Ali from Mumbai|           1126|\n",
            "|       102| Neha|   neha@yahoo.com|  Delhi|2023-01-15|   Neha from Delhi|            876|\n",
            "|       103| Ravi| ravi@hotmail.com|Unknown|2021-11-01| Ravi from Unknown|           1316|\n",
            "|       104|Sneha|sneha@outlook.com|Unknown|2020-07-22|Sneha from Unknown|           1783|\n",
            "|       105| Amit|   amit@gmail.com|Chennai|2023-03-10| Amit from Chennai|            822|\n",
            "+----------+-----+-----------------+-------+----------+------------------+---------------+\n",
            "\n",
            "+-------+----------+--------------+\n",
            "|OrderId| OrderDate|OrderMonthName|\n",
            "+-------+----------+--------------+\n",
            "|      1|2024-01-10|       January|\n",
            "|      2|2024-01-15|       January|\n",
            "|      3|2024-02-01|      February|\n",
            "|      4|2024-02-10|      February|\n",
            "|      5|2024-02-15|      February|\n",
            "|      6|2024-03-01|         March|\n",
            "|      7|2024-03-02|         March|\n",
            "+-------+----------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7.UDFs and Complex Logic\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "# Write a UDF to tag customers:\n",
        "# “Gold” if spend >\n",
        "# 50K, “Silver” if 10K–50K, “Bronze” if <10K.\n",
        "\n",
        "def tag_customer(spend):\n",
        "    if spend > 50000:\n",
        "        return \"Gold\"\n",
        "    elif spend >= 10000:\n",
        "        return \"Silver\"\n",
        "    else:\n",
        "        return \"Bronze\"\n",
        "\n",
        "tag_udf = udf(tag_customer, StringType())\n",
        "\n",
        "customer_spend_df = orders_df.groupBy(\"CustomerID\").sum(\"TotalAmount\") \\\n",
        "    .withColumnRenamed(\"sum(TotalAmount)\", \"TotalSpend\")\n",
        "\n",
        "tag_customers_df = customer_spend_df.withColumn(\"Tag\", tag_udf(col(\"TotalSpend\")))\n",
        "\n",
        "tag_customers_df.show()\n"
      ],
      "metadata": {
        "id": "D3ab7vN-_372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5504a7ad-ff7f-4837-a3be-2942d4cf7e78"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+------+\n",
            "|CustomerID|TotalSpend|   Tag|\n",
            "+----------+----------+------+\n",
            "|       101|  101200.0|  Gold|\n",
            "|       103|    3500.0|Bronze|\n",
            "|       102|   50000.0|Silver|\n",
            "|       105|    2500.0|Bronze|\n",
            "|       104|    5000.0|Bronze|\n",
            "+----------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def shorten_name(name):\n",
        "    return name[:3] + \"...\" if len(name) > 3 else name\n",
        "\n",
        "shorten_udf = udf(shorten_name, StringType())\n",
        "\n",
        "orders_shorten= orders_df.withColumn(\"ShortProduct\", shorten_udf(col(\"Product\")))\n",
        "\n",
        "orders_shorten.select(\"Product\", \"ShortProduct\").show()\n"
      ],
      "metadata": {
        "id": "GCn8IHbTAAi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01dc23b3-353c-4fa6-cf92-7551b95a857c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+\n",
            "|  Product|ShortProduct|\n",
            "+---------+------------+\n",
            "|   Laptop|      Lap...|\n",
            "|    Mouse|      Mou...|\n",
            "|   Tablet|      Tab...|\n",
            "|Bookshelf|      Boo...|\n",
            "|    Mixer|      Mix...|\n",
            "| Notebook|      Not...|\n",
            "|    Phone|      Pho...|\n",
            "+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8.Parquet & Views\n",
        "# Save the joined result as a Parquet file.\n",
        "joined_df = customers_df.join(orders_df, on=\"CustomerID\", how=\"inner\")\n",
        "\n",
        "joined_df.write.mode(\"overwrite\").parquet(\"joined_orders.parquet\")\n"
      ],
      "metadata": {
        "id": "QmgG33LfACRY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read it back and verify schema.\n",
        "parquet_df = spark.read.parquet(\"joined_orders.parquet\")\n",
        "parquet_df.printSchema()\n",
        "parquet_df.show()\n"
      ],
      "metadata": {
        "id": "kQ7fmdY6AEO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3b4c24-5b6a-4f49-a1db-2e3bc76d2193"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Email: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- SignupDate: date (nullable = true)\n",
            " |-- OrderID: integer (nullable = true)\n",
            " |-- Product: string (nullable = true)\n",
            " |-- Category: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- Price: double (nullable = true)\n",
            " |-- OrderDate: date (nullable = true)\n",
            " |-- TotalAmount: double (nullable = true)\n",
            " |-- OrderYear: integer (nullable = true)\n",
            "\n",
            "+----------+-----+-----------------+---------+----------+-------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|OrderID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|\n",
            "+----------+-----+-----------------+---------+----------+-------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "|       101|  Ali|    ali@gmail.com|   Mumbai|2022-05-10|      1|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|\n",
            "|       101|  Ali|    ali@gmail.com|   Mumbai|2022-05-10|      2|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|\n",
            "|       102| Neha|   neha@yahoo.com|    Delhi|2023-01-15|      3|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|\n",
            "|       103| Ravi| ravi@hotmail.com|Bangalore|2021-11-01|      4|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|\n",
            "|       104|Sneha|sneha@outlook.com|Hyderabad|2020-07-22|      5|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|\n",
            "|       105| Amit|   amit@gmail.com|  Chennai|2023-03-10|      6| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|\n",
            "|       102| Neha|   neha@yahoo.com|    Delhi|2023-01-15|      7|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|\n",
            "+----------+-----+-----------------+---------+----------+-------+---------+-----------+--------+-------+----------+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and query a global temp view.\n",
        "parquet_df.createOrReplaceGlobalTempView(\"global_joined_orders\")\n",
        "\n",
        "spark.sql(\"select * from global_temp.global_joined_orders where TotalAmount > 10000\").show()\n"
      ],
      "metadata": {
        "id": "r0ksiwwlAGCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35326f33-2d0c-4b30-a8a1-2865d6f62751"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+--------------+------+----------+-------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "|CustomerID|Name|         Email|  City|SignupDate|OrderID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|\n",
            "+----------+----+--------------+------+----------+-------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "|       101| Ali| ali@gmail.com|Mumbai|2022-05-10|      1| Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|\n",
            "|       102|Neha|neha@yahoo.com| Delhi|2023-01-15|      3| Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|\n",
            "|       102|Neha|neha@yahoo.com| Delhi|2023-01-15|      7|  Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|\n",
            "+----------+----+--------------+------+----------+-------+-------+-----------+--------+-------+----------+-----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Compare performance between CSV read and Parquet read.\n",
        "start_csv = time.time()\n",
        "csv_df = spark.read.csv(\"orders.csv\", header=True, inferSchema=True)\n",
        "csv_df.count()\n",
        "end_csv = time.time()\n",
        "\n",
        "start_parquet = time.time()\n",
        "parquet_df = spark.read.parquet(\"joined_orders.parquet\")\n",
        "parquet_df.count()\n",
        "end_parquet = time.time()\n",
        "\n",
        "print(f\"CSV Read Time: {end_csv - start_csv:.4f} sec\")\n",
        "print(f\"Parquet Read Time: {end_parquet - start_parquet:.4f} sec\")\n"
      ],
      "metadata": {
        "id": "3Kx2FZUNAIXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dff122d-2ff8-42b3-e936-a86b5da55a55"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV Read Time: 1.5067 sec\n",
            "Parquet Read Time: 0.7294 sec\n"
          ]
        }
      ]
    }
  ]
}