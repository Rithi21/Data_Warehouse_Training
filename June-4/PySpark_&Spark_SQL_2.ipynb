{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr\n",
        "spark = SparkSession.builder.appName(\"PracticeProject\").enableHiveSupport().getOrCreate()\n",
        "# Customers Data\n",
        "customers_data = [\n",
        "(101, 'Ali', 'ali@gmail.com', 'Mumbai', '2022-05-10'),\n",
        "(102, 'Neha', 'neha@yahoo.com', 'Delhi', '2023-01-15'),\n",
        "(103, 'Ravi', 'ravi@hotmail.com', 'Bangalore', '2021-11-01'),\n",
        "(104, 'Sneha', 'sneha@outlook.com', 'Hyderabad', '2020-07-22'),\n",
        "(105, 'Amit', 'amit@gmail.com', 'Chennai', '2023-03-10'),\n",
        "]\n",
        "orders_data = [\n",
        "(1, 101, 'Laptop', 'Electronics', 2, 50000.0, '2024-01-10'),\n",
        "(2, 101, 'Mouse', 'Electronics', 1, 1200.0, '2024-01-15'),\n",
        "(3, 102, 'Tablet', 'Electronics', 1, 20000.0, '2024-02-01'),\n",
        "(4, 103, 'Bookshelf', 'Furniture', 1, 3500.0, '2024-02-10'),\n",
        "(5, 104, 'Mixer', 'Appliances', 1, 5000.0, '2024-02-15'),\n",
        "(6, 105, 'Notebook', 'Stationery', 5, 500.0, '2024-03-01'),\n",
        "(7, 102, 'Phone', 'Electronics', 1, 30000.0, '2024-03-02'),\n",
        "]\n",
        "customers_df = spark.createDataFrame(customers_data, [\"CustomerID\", \"Name\", \"Email\",\n",
        "\"City\", \"SignupDate\"])\n",
        "orders_df = spark.createDataFrame(orders_data, [\"OrderID\", \"CustomerID\", \"Product\",\n",
        "\"Category\", \"Quantity\", \"Price\", \"OrderDate\"])\n",
        "\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS sales\")\n",
        "\n",
        "customers_df.write.mode(\"overwrite\").saveAsTable(\"sales.customers\")\n",
        "orders_df.write.mode(\"overwrite\").saveAsTable(\"sales.orders\")"
      ],
      "metadata": {
        "id": "vMGS9bd0IAG3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLokXhGSH-z5",
        "outputId": "b96a7b2d-25af-46a0-8eb3-a131fe4fb2a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderCategory|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|         High|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|          Low|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|       Medium|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|          Low|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|       Medium|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|          Low|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|         High|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderCategory|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "|      1|       101| Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|         High|\n",
            "|      3|       102| Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|       Medium|\n",
            "|      7|       102|  Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|         High|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "|       101|  Ali|    ali@gmail.com|   mumbai|2022-05-10|\n",
            "|       102| Neha|   neha@yahoo.com|    delhi|2023-01-15|\n",
            "|       103| Ravi| ravi@hotmail.com|bangalore|2021-11-01|\n",
            "|       104|Sneha|sneha@outlook.com|hyderabad|2020-07-22|\n",
            "|       105| Amit|   amit@gmail.com|  chennai|2023-03-10|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderCategory|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|         High|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|          Low|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|       Medium|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|          Low|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|       Medium|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|          Low|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|         High|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "|CustomerID| Name|            Email|     City|SignupDate|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "|       101|  Ali|    ali@gmail.com|   mumbai|2022-05-10|\n",
            "|       102| Neha|   neha@yahoo.com|    delhi|2023-01-15|\n",
            "|       103| Ravi| ravi@hotmail.com|bangalore|2021-11-01|\n",
            "|       104|Sneha|sneha@outlook.com|hyderabad|2020-07-22|\n",
            "|       105| Amit|   amit@gmail.com|  chennai|2023-03-10|\n",
            "+----------+-----+-----------------+---------+----------+\n",
            "\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "|OrderID|CustomerID|  Product|   Category|Quantity|  Price| OrderDate|TotalAmount|OrderYear|OrderCategory|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "|      1|       101|   Laptop|Electronics|       2|50000.0|2024-01-10|   100000.0|     2024|         High|\n",
            "|      2|       101|    Mouse|Electronics|       1| 1200.0|2024-01-15|     1200.0|     2024|          Low|\n",
            "|      3|       102|   Tablet|Electronics|       1|20000.0|2024-02-01|    20000.0|     2024|       Medium|\n",
            "|      4|       103|Bookshelf|  Furniture|       1| 3500.0|2024-02-10|     3500.0|     2024|          Low|\n",
            "|      5|       104|    Mixer| Appliances|       1| 5000.0|2024-02-15|     5000.0|     2024|       Medium|\n",
            "|      6|       105| Notebook| Stationery|       5|  500.0|2024-03-01|     2500.0|     2024|          Low|\n",
            "|      7|       102|    Phone|Electronics|       1|30000.0|2024-03-02|    30000.0|     2024|         High|\n",
            "+-------+----------+---------+-----------+--------+-------+----------+-----------+---------+-------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, lower, year, when\n",
        "\n",
        "# 1. Add column TotalAmount = Price * Quantity\n",
        "orders_df = orders_df.withColumn(\"TotalAmount\", col(\"Price\") * col(\"Quantity\"))\n",
        "orders_df.show()\n",
        "# 2. Filter orders with TotalAmount > 10000\n",
        "high_value_orders_df = orders_df.filter(col(\"TotalAmount\") > 10000)\n",
        "high_value_orders_df.show()\n",
        "\n",
        "# 3. Standardize the City field in customers_df\n",
        "customers_df = customers_df.withColumn(\"City\", lower(col(\"City\")))\n",
        "customers_df.show()\n",
        "\n",
        "# 4. Extract year from OrderDate and add OrderYear column\n",
        "orders_df = orders_df.withColumn(\"OrderYear\", year(col(\"OrderDate\")))\n",
        "orders_df.show()\n",
        "\n",
        "# 5. Fill nulls in any column\n",
        "customers_df = customers_df.fillna({'Email':'unknown@yahoo.com'})\n",
        "customers_df.show()\n",
        "\n",
        "# 6. Categorize orders based on TotalAmount\n",
        "orders_df = orders_df.withColumn(\n",
        "    \"OrderCategory\",\n",
        "    when(col(\"TotalAmount\") < 5000, \"Low\")\n",
        "    .when((col(\"TotalAmount\") >= 5000) & (col(\"TotalAmount\") <= 20000), \"Medium\")\n",
        "    .otherwise(\"High\")\n",
        ")\n",
        "orders_df.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SECTION B: Spark SQL Tasks\n",
        "# 7. Run a SQL query to list all orders made by “Ali”.\n",
        "spark.sql(\"\"\"\n",
        "    select o.* from sales.orders o\n",
        "    JOIN sales.customers c ON o.CustomerID = c.CustomerID\n",
        "    where c.Name = 'Ali'\n",
        "\"\"\").show()\n",
        "\n",
        "# 8. Get total spending by each customer using SQL.\n",
        "spark.sql(\"\"\"\n",
        "    select c.Name, SUM(o.Price * o.Quantity) AS TotalSpending\n",
        "    from sales.orders o\n",
        "    JOIN sales.customers c ON o.CustomerID = c.CustomerID\n",
        "    GROUP BY c.Name\n",
        "\"\"\").show()\n",
        "\n",
        "# 9. Find out which category made the highest total revenue.\n",
        "spark.sql(\"\"\"\n",
        "    select Category, SUM(Price * Quantity) AS Revenue\n",
        "    from sales.orders\n",
        "    GROUP BY Category\n",
        "    ORDER BY Revenue DESC\n",
        "    LIMIT 1\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIJeDbjbIG-B",
        "outputId": "2b4e1146-221c-486d-a087-8f3af5a157fd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+-------+-----------+--------+-------+----------+\n",
            "|OrderID|CustomerID|Product|   Category|Quantity|  Price| OrderDate|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+\n",
            "|      1|       101| Laptop|Electronics|       2|50000.0|2024-01-10|\n",
            "|      2|       101|  Mouse|Electronics|       1| 1200.0|2024-01-15|\n",
            "+-------+----------+-------+-----------+--------+-------+----------+\n",
            "\n",
            "+-----+-------------+\n",
            "| Name|TotalSpending|\n",
            "+-----+-------------+\n",
            "| Neha|      50000.0|\n",
            "|  Ali|     101200.0|\n",
            "| Ravi|       3500.0|\n",
            "|Sneha|       5000.0|\n",
            "| Amit|       2500.0|\n",
            "+-----+-------------+\n",
            "\n",
            "+-----------+--------+\n",
            "|   Category| Revenue|\n",
            "+-----------+--------+\n",
            "|Electronics|151200.0|\n",
            "+-----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Create a view customer_orders showing CustomerName, Product, TotalAmount .\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "    CREATE OR REPLACE TEMP VIEW customer_orders AS\n",
        "    select c.Name AS CustomerName, o.Product, (o.Price * o.Quantity) AS TotalAmount\n",
        "    from sales.orders o\n",
        "    JOIN sales.customers c ON o.CustomerID = c.CustomerID\n",
        "\"\"\")\n",
        "\n",
        "# 11. Query the view for products ordered after Feb 2024.\n",
        "spark.sql(\"\"\"\n",
        "    select * from customer_orders\n",
        "    JOIN sales.orders o ON customer_orders.Product = o.Product\n",
        "    WHERE o.OrderDate > '2024-02-29'\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN3r_z65IG0i",
        "outputId": "cc24c013-b17e-4650-9a2b-412aedd74ca2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------+-----------+-------+----------+--------+-----------+--------+-------+----------+\n",
            "|CustomerName| Product|TotalAmount|OrderID|CustomerID| Product|   Category|Quantity|  Price| OrderDate|\n",
            "+------------+--------+-----------+-------+----------+--------+-----------+--------+-------+----------+\n",
            "|        Amit|Notebook|     2500.0|      6|       105|Notebook| Stationery|       5|  500.0|2024-03-01|\n",
            "|        Neha|   Phone|    30000.0|      7|       102|   Phone|Electronics|       1|30000.0|2024-03-02|\n",
            "+------------+--------+-----------+-------+----------+--------+-----------+--------+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SECTION C: Advanced Practice\n",
        "# 12. Create a Global Temp View from customers_df\n",
        "customers_df.createOrReplaceGlobalTempView(\"customers\")\n",
        "\n",
        "spark.sql(\"SELECT * FROM global_temp.customers where City = 'mumbai'\").show()\n",
        "\n",
        "#13. Save the transformed orders_df (with TotalAmount) to a Parquet file.\n",
        "orders_df.write.mode(\"overwrite\").parquet(\"/tmp/orders_parquet\")\n",
        "\n",
        "#14. Read back the Parquet file and count how many orders are in it.\n",
        "orders_parquet_df = spark.read.parquet(\"/tmp/orders_parquet\")\n",
        "orders_parquet_df.count()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9DS6rfYIP3U",
        "outputId": "dbb17518-3fe8-4d7f-9364-47eadd0971b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+-------------+------+----------+\n",
            "|CustomerID|Name|        Email|  City|SignupDate|\n",
            "+----------+----+-------------+------+----------+\n",
            "|       101| Ali|ali@gmail.com|mumbai|2022-05-10|\n",
            "+----------+----+-------------+------+----------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. Write a UDF that masks emails like: ali@gmail.com → a***@gmail.com .\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def mask_email(email):\n",
        "    try:\n",
        "        name, domain = email.split('@')\n",
        "        return name[0] + '***@' + domain\n",
        "    except:\n",
        "        return email\n",
        "\n",
        "mask_email_udf = udf(mask_email, StringType())\n",
        "\n",
        "customers_df = customers_df.withColumn(\"MaskedEmail\", mask_email_udf(col(\"Email\")))\n",
        "customers_df.select(\"Email\", \"MaskedEmail\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-xbYpUbIVNX",
        "outputId": "8b216d89-55b8-4008-b095-1484a5f0b1f5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------------+\n",
            "|            Email|     MaskedEmail|\n",
            "+-----------------+----------------+\n",
            "|    ali@gmail.com|  a***@gmail.com|\n",
            "|   neha@yahoo.com|  n***@yahoo.com|\n",
            "| ravi@hotmail.com|r***@hotmail.com|\n",
            "|sneha@outlook.com|s***@outlook.com|\n",
            "|   amit@gmail.com|  a***@gmail.com|\n",
            "+-----------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 16. Use concat_ws() to create a full label like: 'Ali from Mumbai'\n",
        "\n",
        "from pyspark.sql.functions import concat_ws\n",
        "\n",
        "customers_df = customers_df.withColumn(\"Label\", concat_ws(\" from \", col(\"Name\"), col(\"City\")))\n",
        "customers_df.select(\"Name\", \"City\", \"Label\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFRvWzc5Ibhv",
        "outputId": "73212487-6967-43f5-ad95-435fa9965297"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+--------------------+\n",
            "| Name|     City|               Label|\n",
            "+-----+---------+--------------------+\n",
            "|  Ali|   mumbai|     Ali from mumbai|\n",
            "| Neha|    delhi|     Neha from delhi|\n",
            "| Ravi|bangalore| Ravi from bangalore|\n",
            "|Sneha|hyderabad|Sneha from hyderabad|\n",
            "| Amit|  chennai|   Amit from chennai|\n",
            "+-----+---------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#17. Use regexp_replace() to remove special characters from product names.\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "orders_df = orders_df.withColumn(\"CleanProduct\", regexp_replace(col(\"Product\"), \"[^a-zA-Z0-9 ]\", \"\"))\n",
        "orders_df.select(\"Product\", \"CleanProduct\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epZUtPRHIbU6",
        "outputId": "3e87a893-4a17-497d-a834-b970c3318e2a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+\n",
            "|  Product|CleanProduct|\n",
            "+---------+------------+\n",
            "|   Laptop|      Laptop|\n",
            "|    Mouse|       Mouse|\n",
            "|   Tablet|      Tablet|\n",
            "|Bookshelf|   Bookshelf|\n",
            "|    Mixer|       Mixer|\n",
            "| Notebook|    Notebook|\n",
            "|    Phone|       Phone|\n",
            "+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 18. Use to_date() and datediff() to calculate customer age in days (from\n",
        "# SignupDate to today).\n",
        "from pyspark.sql.functions import to_date, current_date, datediff\n",
        "\n",
        "customers_df = customers_df.withColumn(\"SignupDate\", to_date(col(\"SignupDate\")))\n",
        "customers_df = customers_df.withColumn(\"CustomerAgeDays\", datediff(current_date(), col(\"SignupDate\")))\n",
        "customers_df.select(\"Name\", \"SignupDate\", \"CustomerAgeDays\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NP1o5R1SIbNc",
        "outputId": "465a21d3-3bba-4686-d517-227e591dcd78"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+---------------+\n",
            "| Name|SignupDate|CustomerAgeDays|\n",
            "+-----+----------+---------------+\n",
            "|  Ali|2022-05-10|           1121|\n",
            "| Neha|2023-01-15|            871|\n",
            "| Ravi|2021-11-01|           1311|\n",
            "|Sneha|2020-07-22|           1778|\n",
            "| Amit|2023-03-10|            817|\n",
            "+-----+----------+---------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}